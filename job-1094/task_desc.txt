你需要撰写优化**用户消息审查**这个问题的业务逻辑，提升 **f1 score**。
该代码应当自恰，其中一定包括一个函数接口 `inference_function`。这个函数的签名如下：

async def inference_function(
        batch_idx: int,
        df_input: pd.DataFrame,
):
    """
    以 DataFrame 格式提供一条待审查数据，并以 DataFrame 格式返回审查结果

    Parameters
    ----------
    batch_idx: int
        Just a indicator what batch this is, for later gather the results

    df_input: pd.DataFrame
        The input data containing one row with three columns:
            'id': (string) used to identify each sample
            'comment': (string) one sentence that need to be judged if it violates the rules
            'content': (string) the conversation context that this comment is in

    Returns
    -------
    batch_idx: int
        Just a indicator what batch this is, for later gather the results

    df_output: pd.DataFrame or None
        The processed output DataFrame with the same 'id' values as the input,
        and 'predicted' column, 1 if violating the rule, 0 if normal
        or None if the inference fails after multiple retries.
    
    raw_res: string
        raw string response from llm
    """

如果想用调用大模型，可以使用环境变量 `MODEL_NAME` 和 `OPENAI_API_KEY` 去调用 LLM 生成结果，调用 API 的 base url 是 `https://llm-api.p1.cn`。

在保证 inference_function 接口不变的情况下，请用任意方法，修改 prompt / 修改推理逻辑 / 修改 llm 格式与解析逻辑等，提升 f1 score 。

注意：
1. 在 inference_function 函数中，你可以自行修改代码里面解析LLM输出的逻辑，以及对于LLM生成要求的指令。一般而言，大模型会更喜欢符合自然语言习惯、流畅的文本表述。

## f1 score 如何计算
随机抽样 n 条用户消息数据作为输入，输出审核结果。

evaluate 程序调用解析 inference_function 输出的 DataFrame ，通过对比同一个 id 的预测结果 (predicted) 和人工标注的值, 计算 precision 和 recall
最终的 f1_score = (2 * precision * recall) / (precision + recall)

你可以选择在 inference_function 中使用如下辅助函数：

def get_embeddings(
    inputs: Union[str, Sequence[str]],
    dim: Literal[2048, 1024, 512, 256] = 2048,
    timeout: float = 30.0,
) -> List[List[float]]:
    """
    Call Jarvis embeddings API and return vectors with the same length as inputs.

    Args:
        inputs: a single text or a list of texts
        dim: keep only the first N dimensions; must be one of {2048, 1024, 512, 256}
        timeout: request timeout in seconds

    Returns: embedding vectors with the same length as inputs
    """